{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "DIR = '/export/share/yutong/xgenmm/llamacpp_wd/siglip_kosmos_phi3_4k_instruct'\n",
    "ckpt = torch.load(DIR + '/xgenmm.projector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['latents', 'projection.weight', 'projection.bias', 'layers.0.0.norm_media.weight', 'layers.0.0.norm_media.bias', 'layers.0.0.norm_latents.weight', 'layers.0.0.norm_latents.bias', 'layers.0.0.to_q.weight', 'layers.0.0.to_kv.weight', 'layers.0.0.to_out.weight', 'layers.0.1.0.weight', 'layers.0.1.0.bias', 'layers.0.1.1.weight', 'layers.0.1.3.weight', 'layers.1.0.norm_media.weight', 'layers.1.0.norm_media.bias', 'layers.1.0.norm_latents.weight', 'layers.1.0.norm_latents.bias', 'layers.1.0.to_q.weight', 'layers.1.0.to_kv.weight', 'layers.1.0.to_out.weight', 'layers.1.1.0.weight', 'layers.1.1.0.bias', 'layers.1.1.1.weight', 'layers.1.1.3.weight', 'layers.2.0.norm_media.weight', 'layers.2.0.norm_media.bias', 'layers.2.0.norm_latents.weight', 'layers.2.0.norm_latents.bias', 'layers.2.0.to_q.weight', 'layers.2.0.to_kv.weight', 'layers.2.0.to_out.weight', 'layers.2.1.0.weight', 'layers.2.1.0.bias', 'layers.2.1.1.weight', 'layers.2.1.3.weight', 'layers.3.0.norm_media.weight', 'layers.3.0.norm_media.bias', 'layers.3.0.norm_latents.weight', 'layers.3.0.norm_latents.bias', 'layers.3.0.to_q.weight', 'layers.3.0.to_kv.weight', 'layers.3.0.to_out.weight', 'layers.3.1.0.weight', 'layers.3.1.0.bias', 'layers.3.1.1.weight', 'layers.3.1.3.weight', 'layers.4.0.norm_media.weight', 'layers.4.0.norm_media.bias', 'layers.4.0.norm_latents.weight', 'layers.4.0.norm_latents.bias', 'layers.4.0.to_q.weight', 'layers.4.0.to_kv.weight', 'layers.4.0.to_out.weight', 'layers.4.1.0.weight', 'layers.4.1.0.bias', 'layers.4.1.1.weight', 'layers.4.1.3.weight', 'layers.5.0.norm_media.weight', 'layers.5.0.norm_media.bias', 'layers.5.0.norm_latents.weight', 'layers.5.0.norm_latents.bias', 'layers.5.0.to_q.weight', 'layers.5.0.to_kv.weight', 'layers.5.0.to_out.weight', 'layers.5.1.0.weight', 'layers.5.1.0.bias', 'layers.5.1.1.weight', 'layers.5.1.3.weight', 'norm.weight', 'norm.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(ckpt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1152])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt['latents'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1152])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt['latents'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1536, 1152]), torch.Size([3072, 1152]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt['layers.0.0.to_q.weight'].shape, ckpt['layers.0.0.to_kv.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1536, 1152]), torch.Size([1536, 1152]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt['layers.0.0.to_kv.weight'].chunk(2, dim=0)[0].shape, ckpt['layers.0.0.to_kv.weight'].chunk(2, dim=0)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.norm_media.weight\n",
      "layers.0.0.norm_media.bias\n",
      "layers.0.0.norm_latents.weight\n",
      "layers.0.0.norm_latents.bias\n",
      "layers.0.0.to_q.weight\n",
      "layers.0.0.to_kv.weight\n",
      "layers.0.0.to_out.weight\n",
      "layers.0.1.0.weight\n",
      "layers.0.1.0.bias\n",
      "layers.0.1.1.weight\n",
      "layers.0.1.3.weight\n"
     ]
    }
   ],
   "source": [
    "for k in ckpt.keys():\n",
    "    if 'layers.0' in k:\n",
    "        print(k)\n",
    "        \n",
    "def _replace_attn_layer(key, value):\n",
    "    # Check for the special case first\n",
    "    if re.match(r'layers\\.(\\d+)\\.0\\.to_kv\\.weight', key):\n",
    "        idx = re.search(r'layers\\.(\\d+)\\.0\\.to_kv\\.weight', key).group(1)\n",
    "        KVweight = value.chunk(2, dim=0)\n",
    "        return {f'blk.{idx}.attn.to_k.weight': KVweight[0],\n",
    "                f'blk.{idx}.attn.to_v.weight': KVweight[1]\n",
    "                }\n",
    "    \n",
    "    # Apply general replacements for other patterns\n",
    "    # Define the replacement patterns\n",
    "    patterns = [\n",
    "        (r'layers\\.(\\d+)\\.0\\.norm_media\\.(weight|bias)', r'blk.\\1.attn.norm_media.\\2'),\n",
    "        (r'layers\\.(\\d+)\\.0\\.norm_latents\\.(weight|bias)', r'blk.\\1.attn.norm_latents.\\2'),\n",
    "        (r'layers\\.(\\d+)\\.0\\.to_q\\.(weight)', r'blk.\\1.attn.to_q.\\2'),\n",
    "        (r'layers\\.(\\d+)\\.0\\.to_out\\.(weight)', r'blk.\\1.attn.to_out.\\2'),\n",
    "        (r'layers\\.(\\d+)\\.1\\.0\\.(weight|bias)', r'blk.\\1.ffn.ln.\\2'),\n",
    "        (r'layers\\.(\\d+)\\.1\\.1\\.weight', r'blk.\\1.ffn.linear_up.weight'),\n",
    "        (r'layers\\.(\\d+)\\.1\\.3\\.weight', r'blk.\\1.ffn.linear_down.weight'),\n",
    "    ]\n",
    "    for pattern, replacement in patterns:\n",
    "        key = re.sub(pattern, replacement, key)\n",
    "    \n",
    "    return {key: value}\n",
    "\n",
    "def replace_tensor_name_xgenmm_projector(ckpt):\n",
    "    identifier = 'perceiver_resampler.'\n",
    "    new_state_dict = {}\n",
    "    for k, v in ckpt.items():\n",
    "        # handel the layer\n",
    "        if 'layers' in k:\n",
    "            new_kvs = _replace_attn_layer(k, v)\n",
    "            for new_k, new_v in new_kvs.items():\n",
    "                new_state_dict[identifier+new_k] = new_v\n",
    "        elif k == 'norm.weight':\n",
    "            new_k = 'ln.weight'\n",
    "            new_state_dict[identifier+new_k] = v\n",
    "        elif k == 'norm.bias':\n",
    "            new_k = 'ln.bias'\n",
    "            new_state_dict[identifier+new_k] = v  \n",
    "        else:\n",
    "            new_state_dict[identifier+k] = v\n",
    "    return new_state_dict     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "projector = replace_tensor_name_xgenmm_projector(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['perceiver_resampler.latents',\n",
       " 'perceiver_resampler.projection.weight',\n",
       " 'perceiver_resampler.projection.bias',\n",
       " 'perceiver_resampler.blk.0.attn.norm_media.weight',\n",
       " 'perceiver_resampler.blk.0.attn.norm_media.bias',\n",
       " 'perceiver_resampler.blk.0.attn.norm_latents.weight',\n",
       " 'perceiver_resampler.blk.0.attn.norm_latents.bias',\n",
       " 'perceiver_resampler.blk.0.attn.to_q.weight',\n",
       " 'perceiver_resampler.blk.0.attn.to_k.weight',\n",
       " 'perceiver_resampler.blk.0.attn.to_v.weight',\n",
       " 'perceiver_resampler.blk.0.attn.to_out.weight',\n",
       " 'perceiver_resampler.blk.0.ffn.ln.weight',\n",
       " 'perceiver_resampler.blk.0.ffn.ln.bias',\n",
       " 'perceiver_resampler.blk.0.ffn.linear_up.weight',\n",
       " 'perceiver_resampler.blk.0.ffn.linear_down.weight',\n",
       " 'perceiver_resampler.blk.1.attn.norm_media.weight',\n",
       " 'perceiver_resampler.blk.1.attn.norm_media.bias',\n",
       " 'perceiver_resampler.blk.1.attn.norm_latents.weight',\n",
       " 'perceiver_resampler.blk.1.attn.norm_latents.bias',\n",
       " 'perceiver_resampler.blk.1.attn.to_q.weight',\n",
       " 'perceiver_resampler.blk.1.attn.to_k.weight',\n",
       " 'perceiver_resampler.blk.1.attn.to_v.weight',\n",
       " 'perceiver_resampler.blk.1.attn.to_out.weight',\n",
       " 'perceiver_resampler.blk.1.ffn.ln.weight',\n",
       " 'perceiver_resampler.blk.1.ffn.ln.bias',\n",
       " 'perceiver_resampler.blk.1.ffn.linear_up.weight',\n",
       " 'perceiver_resampler.blk.1.ffn.linear_down.weight',\n",
       " 'perceiver_resampler.blk.2.attn.norm_media.weight',\n",
       " 'perceiver_resampler.blk.2.attn.norm_media.bias',\n",
       " 'perceiver_resampler.blk.2.attn.norm_latents.weight',\n",
       " 'perceiver_resampler.blk.2.attn.norm_latents.bias',\n",
       " 'perceiver_resampler.blk.2.attn.to_q.weight',\n",
       " 'perceiver_resampler.blk.2.attn.to_k.weight',\n",
       " 'perceiver_resampler.blk.2.attn.to_v.weight',\n",
       " 'perceiver_resampler.blk.2.attn.to_out.weight',\n",
       " 'perceiver_resampler.blk.2.ffn.ln.weight',\n",
       " 'perceiver_resampler.blk.2.ffn.ln.bias',\n",
       " 'perceiver_resampler.blk.2.ffn.linear_up.weight',\n",
       " 'perceiver_resampler.blk.2.ffn.linear_down.weight',\n",
       " 'perceiver_resampler.blk.3.attn.norm_media.weight',\n",
       " 'perceiver_resampler.blk.3.attn.norm_media.bias',\n",
       " 'perceiver_resampler.blk.3.attn.norm_latents.weight',\n",
       " 'perceiver_resampler.blk.3.attn.norm_latents.bias',\n",
       " 'perceiver_resampler.blk.3.attn.to_q.weight',\n",
       " 'perceiver_resampler.blk.3.attn.to_k.weight',\n",
       " 'perceiver_resampler.blk.3.attn.to_v.weight',\n",
       " 'perceiver_resampler.blk.3.attn.to_out.weight',\n",
       " 'perceiver_resampler.blk.3.ffn.ln.weight',\n",
       " 'perceiver_resampler.blk.3.ffn.ln.bias',\n",
       " 'perceiver_resampler.blk.3.ffn.linear_up.weight',\n",
       " 'perceiver_resampler.blk.3.ffn.linear_down.weight',\n",
       " 'perceiver_resampler.blk.4.attn.norm_media.weight',\n",
       " 'perceiver_resampler.blk.4.attn.norm_media.bias',\n",
       " 'perceiver_resampler.blk.4.attn.norm_latents.weight',\n",
       " 'perceiver_resampler.blk.4.attn.norm_latents.bias',\n",
       " 'perceiver_resampler.blk.4.attn.to_q.weight',\n",
       " 'perceiver_resampler.blk.4.attn.to_k.weight',\n",
       " 'perceiver_resampler.blk.4.attn.to_v.weight',\n",
       " 'perceiver_resampler.blk.4.attn.to_out.weight',\n",
       " 'perceiver_resampler.blk.4.ffn.ln.weight',\n",
       " 'perceiver_resampler.blk.4.ffn.ln.bias',\n",
       " 'perceiver_resampler.blk.4.ffn.linear_up.weight',\n",
       " 'perceiver_resampler.blk.4.ffn.linear_down.weight',\n",
       " 'perceiver_resampler.blk.5.attn.norm_media.weight',\n",
       " 'perceiver_resampler.blk.5.attn.norm_media.bias',\n",
       " 'perceiver_resampler.blk.5.attn.norm_latents.weight',\n",
       " 'perceiver_resampler.blk.5.attn.norm_latents.bias',\n",
       " 'perceiver_resampler.blk.5.attn.to_q.weight',\n",
       " 'perceiver_resampler.blk.5.attn.to_k.weight',\n",
       " 'perceiver_resampler.blk.5.attn.to_v.weight',\n",
       " 'perceiver_resampler.blk.5.attn.to_out.weight',\n",
       " 'perceiver_resampler.blk.5.ffn.ln.weight',\n",
       " 'perceiver_resampler.blk.5.ffn.ln.bias',\n",
       " 'perceiver_resampler.blk.5.ffn.linear_up.weight',\n",
       " 'perceiver_resampler.blk.5.ffn.linear_down.weight',\n",
       " 'perceiver_resampler.ln.weight',\n",
       " 'perceiver_resampler.ln.bias']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(projector.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05494d31407541bfa3db8f4eb455df9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "213aa24ea7ef48c29cefa8a6b0a0cc97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_minicpm.py:   0%|          | 0.00/10.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/openbmb/MiniCPM-V-2:\n",
      "- configuration_minicpm.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a37bed5d814eed8eeea41caee8b88c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_minicpmv.py:   0%|          | 0.00/20.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "697157f53323482089fcfd4109385476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "resampler.py:   0%|          | 0.00/36.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/openbmb/MiniCPM-V-2:\n",
      "- resampler.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1903bed8794551b0d55d0adc12001b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_minicpm.py:   0%|          | 0.00/71.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/openbmb/MiniCPM-V-2:\n",
      "- modeling_minicpm.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/openbmb/MiniCPM-V-2:\n",
      "- modeling_minicpmv.py\n",
      "- resampler.py\n",
      "- modeling_minicpm.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "982e9ac1698544b6b0e71da45698aa23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/54.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f1e771a0b04575ad8269ebfce0b2af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f894ab4b037470a88e4809ac2d20c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "162978caf34c45f4b94dda25c2cbc7d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f9dfef799646868980ad10fb1be99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e43882325b64e52874ff182dace14d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "model = AutoModel.from_pretrained('openbmb/MiniCPM-V-2', trust_remote_code=True)\n",
    "resampler = model.resampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampler.pos_embed\n",
      "dict_keys(['resampler.pos_embed', 'resampler.pos_embed_k'])\n",
      "===\n",
      "resampler.query\n",
      "dict_keys(['resampler.query'])\n",
      "===\n",
      "resampler.proj\n",
      "dict_keys(['resampler.pos_embed_k', 'resampler.proj.weight'])\n",
      "===\n",
      "resampler.kv_proj.weight\n",
      "dict_keys(['resampler.kv_proj.weight'])\n",
      "===\n",
      "resampler.attn.in_proj_weight\n",
      "dict_keys(['resampler.attn.q.weight', 'resampler.attn.k.weight', 'resampler.attn.v.weight'])\n",
      "===\n",
      "resampler.attn.in_proj_bias\n",
      "dict_keys(['resampler.attn.q.bias', 'resampler.attn.k.bias', 'resampler.attn.v.bias'])\n",
      "===\n",
      "resampler.attn.out_proj.weight\n",
      "dict_keys(['resampler.attn.out_proj.weight'])\n",
      "===\n",
      "resampler.attn.out_proj.bias\n",
      "dict_keys(['resampler.attn.out_proj.bias'])\n",
      "===\n",
      "resampler.ln_q.weight\n",
      "dict_keys(['resampler.ln_q.weight'])\n",
      "===\n",
      "resampler.ln_q.bias\n",
      "dict_keys(['resampler.ln_q.bias'])\n",
      "===\n",
      "resampler.ln_kv.weight\n",
      "dict_keys(['resampler.ln_kv.weight'])\n",
      "===\n",
      "resampler.ln_kv.bias\n",
      "dict_keys(['resampler.ln_kv.bias'])\n",
      "===\n",
      "resampler.ln_post.weight\n",
      "dict_keys(['resampler.ln_post.weight'])\n",
      "===\n",
      "resampler.ln_post.bias\n",
      "dict_keys(['resampler.ln_post.bias'])\n",
      "===\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def _replace_name_resampler(s, v):\n",
    "    if re.match(\"resampler.pos_embed\", s):\n",
    "        return {\n",
    "            s: v,\n",
    "            re.sub(\"pos_embed\", \"pos_embed_k\", s): None,\n",
    "        }\n",
    "    if re.match(\"resampler.proj\", s):\n",
    "        return {\n",
    "            re.sub(\"proj\", \"pos_embed_k\", s): None, \n",
    "            re.sub(\"proj\", \"proj.weight\", s): v.transpose(-1, -2).contiguous(),\n",
    "        }\n",
    "    if re.match(\"resampler.attn.in_proj_.*\", s):\n",
    "        return {\n",
    "            re.sub(\"attn.in_proj_\", \"attn.q.\", s): v.chunk(3, dim=0)[0],\n",
    "            re.sub(\"attn.in_proj_\", \"attn.k.\", s): v.chunk(3, dim=0)[1],\n",
    "            re.sub(\"attn.in_proj_\", \"attn.v.\", s): v.chunk(3, dim=0)[2],\n",
    "        }\n",
    "    return {s: v}\n",
    "\n",
    "res = {}\n",
    "for k in model.state_dict().keys():\n",
    "    if re.match(\"resampler\", k):\n",
    "        print(k)\n",
    "        temp = _replace_name_resampler(k, model.state_dict()[k])\n",
    "        res.update(temp)\n",
    "        print(temp.keys())\n",
    "        print('===')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2304, 2304]), torch.Size([2304, 2304]), torch.Size([2304, 2304]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['resampler.attn.q.weight'].shape, res['resampler.attn.k.weight'].shape, res['resampler.attn.v.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgenmm-flamingo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
